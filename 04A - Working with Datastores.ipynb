{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データストアの使用\n",
    "\n",
    "以前のラボでは、Azure MLワークスペースに接続し、実験スクリプトが実行されているローカルCSVファイルのデータに基づいて簡単な実験を実行しました。ここで、クラウドに保存されたデータを操作します。\n",
    "\n",
    "> **重要**: このノートブックのコードは、[Lab 4A](labdocs/Lab04A.md)の最初の2つのタスクを完了していることを前提としています。まだ行っていない場合は、今すぐ行ってください！\n",
    "\n",
    "## ワークスペースに接続する\n",
    "\n",
    "最初に行う必要があるのは、Azure ML SDKを使用してワークスペースに接続することです。\n",
    "\n",
    "> **Note**: 前の演習を完了してから、Azureサブスクリプションとの認証済みセッションの有効期限が切れた場合、再認証するように求められます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワークスペースでデータストアを表示する\n",
    "\n",
    "ワークスペースには、[前のタスク](labdocs/Lab04A.md)で作成した**aml_data**データストアなど、いくつかのデータストアが含まれています。\n",
    "\n",
    "次のコードを実行して*default*データストアを取得してから、どのデータストアがデフォルトであるかを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用するデータストアを取得する\n",
    "\n",
    "**aml_data**データストアを使用するため、名前で取得する必要があります:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "aml_datastore = Datastore.get(ws, 'aml_data')\n",
    "print(aml_datastore.name,\":\", aml_datastore.datastore_type + \" (\" + aml_datastore.account_name + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デフォルトのデータストアを設定する\n",
    "\n",
    "このコースでは、主に**aml_data**データストアを使用します。便宜上、デフォルトのデータストアになるように設定できます:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.set_default_datastore('aml_data')\n",
    "default_ds = ws.get_default_datastore()\n",
    "print(default_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データストアへのデータのアップロード\n",
    "\n",
    "作業するデータストアを特定したので、実験スクリプトが実際に実行されている場所に関係なく、ワークスペースで実行されている実験にアクセスできるように、ローカルファイルシステムからファイルをアップロードできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                       target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データストアからモデルをトレーニングする\n",
    "\n",
    "上記のコードセルにファイルをアップロードすると、コードが*データ参照*を返したことに注意してください。データ参照は、スクリプトがデータストアの場所にあるデータにアクセスできるように、スクリプトの実行場所に関係なく、データストア内のフォルダーへのパスをスクリプトに渡す方法を提供します。\n",
    "\n",
    "次のコードは、糖尿病CSVファイルをアップロードした**diabetes-data**フォルダーへの参照を取得し、特に*download*のデータ参照を構成します。",
    "つまり、フォルダーの内容をダウンロードするために使用できます。データ参照が使用されている計算コンテキストへ。",
    "データのダウンロードは、ローカルコンピューティングで処理される少量のデータに適しています。",
    "リモートコンピューティングを使用する場合、データストアの場所を*マウント*するようにデータ参照を構成し、データソースから直接データを読み取ることもできます。\n",
    "\n",
    "> **詳しくは**: データストアの使用の詳細については、[Azure MLドキュメント](https://docs.microsoft.com/azure/machine-learning/how-to-access-data)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = default_ds.path('diabetes-data').as_download(path_on_compute='diabetes_data')\n",
    "print(data_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングスクリプトでデータ参照を使用するには、そのパラメーターを定義する必要があります。次の2つのコードセルを実行して作成します:\n",
    "\n",
    "1. **diabetes_training_from_datastore**という名前のフォルダー\n",
    "2. 渡されたデータ参照パラメーターによって参照されるフォルダー内のすべてのCSVファイルのトレーニングデータを使用して、分類モデルをトレーニングするスクリプト。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_datastore'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder reference')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data from the data reference\n",
    "data_folder = args.data_folder\n",
    "print(\"Loading data from\", data_folder)\n",
    "# Load all files and concatenate their contents as a single dataframe\n",
    "all_files = os.listdir(data_folder)\n",
    "diabetes = pd.concat((pd.read_csv(os.path.join(data_folder,csv_file)) for csv_file in all_files))\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スクリプトは、パラメータとして渡されたデータ参照からトレーニングデータをロードするため、実験を実行するときにスクリプトパラメータを設定してファイル参照を渡すだけで済みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Set up the parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1, # regularization rate\n",
    "    '--data-folder': data_ref # data reference to download files from datastore\n",
    "}\n",
    "\n",
    "\n",
    "# Create an estimator\n",
    "estimator = SKLearn(source_directory=experiment_folder,\n",
    "                    entry_script='diabetes_training.py',\n",
    "                    script_params=script_params,\n",
    "                    compute_target = 'local'\n",
    "                   )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実験を初めて実行するときは、Python環境のセットアップに時間がかかる場合があります-以降の実行はより高速になります。\n",
    "\n",
    "実験が完了したら、ウィジェットで**azureml-logs/70_driver_log.txt**出力ログを表示して、データファイルがダウンロードされたことを確認します。\n",
    "\n",
    "すべての実験と同様に、[Azure ML studio](https://ml.azure.com)で実験の詳細を表示し、生成されたメトリックとファイルを取得するコードを作成できます。:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logged metrics\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでも、実験によって訓練されたモデルを登録できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'SKLearn Estimator (using Datastore)'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "# List the registered models\n",
    "print(\"Registered Models:\")\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この演習では、*datastore*の形式でデータを操作するためのいくつかのオプションを検討しました。\n",
    "\n",
    "Azure Machine Learningは、*datasets*の形式でデータの抽象化をさらに強化します。これについては、次に説明します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}