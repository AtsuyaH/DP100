# Lab 7B: バッチ推論サービスの作成

多くのシナリオでは、推論は、予測モデルを使用して多数のケースをスコアリングするバッチプロセスとして実行されます。この種の推論ソリューションをAzure Machine Learningに実装するには、バッチ推論パイプラインを作成できます。

## 始める前に

このラボを開始する前に、[Lab1A](Lab01A.md)および[Lab1B](Lab01B.md)を完了していることを確認してください。これらには、このラボで使用するAzure Machine Learningワークスペースおよびその他のリソースを作成するタスクが含まれています。

## Task 1: バッチ推論サービスを作成する

このタスクでは、バッチ推論パイプラインを作成し、サービスとして公開します。

1. [Azure Machine Learning studio](https://ml.azure.com)で、ワークスペースの**Compute**ページを表示します。 [**Compute Instances**]タブで、コンピューティングインスタンスが実行されていることを確認します。そうでない場合は、開始します。
2. コンピューティングインスタンスの実行中に、**Jupyter**リンクをクリックして、新しいブラウザータブでJupyterホームページを開きます。
3. Jupyterホームページの**Users/DP100**フォルダーで、**07B-バッチ推論Service.ipynb**ノートブックを作成します。次に、ノートブックのメモを読み、各コードセルを順番に実行します。

> **Note**: [次の演習](Lab08A.md)に直接進む場合は、コンピューティングインスタンスを実行したままにします。休憩している場合は、すべてのJupyterタブを閉じてコンピューティングインスタンスを**停止**し、不要なコストが発生しないようにすることができます。
